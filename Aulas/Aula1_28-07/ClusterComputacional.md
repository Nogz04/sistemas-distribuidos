# Aula 1 - Sistemas Paralelos
 
## Sistemas FORTEMENTE acoplados - Cluster Computacional

> - Geograficamente na mesma localizaÃ§Ã£o
> - Hardware igual para todas as maquinas
> - Esquema de comunicaÃ§Ã£o via fibra Ã³ptica
> - Sistema de nobreak robusto
> - Sistema de backup
> - ProgramaÃ§Ã£o paralela


## Cluster Computacional - CaracterÃ­sticas e Componentes

Um **cluster computacional** Ã© um conjunto de computadores interligados que funcionam como uma Ãºnica unidade de processamento. Abaixo estÃ£o os principais elementos citados em aula, com suas respectivas funÃ§Ãµes no contexto de clusters de alto desempenho (HPC).


## ğŸ“ 1. Geograficamente na mesma localizaÃ§Ã£o

- Todos os nÃ³s (computadores) do cluster estÃ£o fisicamente prÃ³ximos.
- Reduz a latÃªncia de comunicaÃ§Ã£o entre as mÃ¡quinas.
- Facilita a manutenÃ§Ã£o e o gerenciamento do sistema.
- Exemplo: todos os nÃ³s em uma mesma sala ou data center.

---

## ğŸ’» 2. Hardware e sistema operacional igual para todas as mÃ¡quinas

- MÃ¡quinas com especificaÃ§Ãµes idÃªnticas (CPU, RAM, disco).
- Garante uniformidade de desempenho.
- Facilita a divisÃ£o de tarefas em paralelo.
- Evita gargalos por desempenho desigual entre os nÃ³s.

---

## ğŸŒ 3. Esquema de comunicaÃ§Ã£o via fibra Ã³ptica

- ConexÃ£o entre nÃ³s usando **fibra Ã³ptica**:
  - Alta velocidade de transmissÃ£o.
  - Baixa latÃªncia.
  - Alta confiabilidade.
- Fundamental para tarefas que exigem troca rÃ¡pida de dados entre os nÃ³s.

---

## ğŸ”‹ 4. Sistema de nobreak robusto

- Garante funcionamento contÃ­nuo mesmo em caso de queda de energia.
- Evita:
  - Perda de dados.
  - Danos ao hardware.
  - InterrupÃ§Ã£o de tarefas em execuÃ§Ã£o.
- Pode ser combinado com **geradores de energia** para maior autonomia.

---

## ğŸ’¾ 5. Sistema de backup

- Protege contra perda de dados e falhas crÃ­ticas.
- Tipos comuns de backup:
  - CÃ³pias regulares de dados dos usuÃ¡rios.
  - Backup de configuraÃ§Ãµes do sistema.
  - Armazenamento em dispositivos externos ou na nuvem.
- Essencial para recuperaÃ§Ã£o de desastres.

---

## ğŸ§  6. ProgramaÃ§Ã£o paralela

- Permite dividir tarefas entre mÃºltiplos nÃ³s do cluster.
- Aumenta a eficiÃªncia no processamento de grandes volumes de dados.
- Tecnologias utilizadas:
  - **MPI (Message Passing Interface)**: comunicaÃ§Ã£o entre nÃ³s distintos.
  - **OpenMP**: paralelismo em mÃºltiplos nÃºcleos da mesma mÃ¡quina.
  - **CUDA**: para processamento paralelo com GPUs.

---
